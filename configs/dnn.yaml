# DNN training configuration for DarkBottomLine framework

# Model architecture
model:
  type: "ParametricDNN"
  input_features: 20  # Number of input features
  hidden_layers: [128, 64, 32]  # Hidden layer sizes
  activation: "relu"  # Activation function
  dropout: 0.2  # Dropout rate
  parametric_input: true  # Include mass parameter as input
  output_activation: "sigmoid"  # Output activation (0-1 for binary classification)

# Training parameters
training:
  batch_size: 1024
  learning_rate: 0.001
  epochs: 100
  early_stopping:
    patience: 10
    min_delta: 0.001
  optimizer: "adam"
  loss_function: "binary_crossentropy"
  metrics: ["accuracy", "auc"]

# Data preprocessing
preprocessing:
  feature_scaling: "standard"  # standard, minmax, robust
  train_validation_split: 0.8  # Fraction for training
  random_seed: 42
  shuffle_data: true

# Input features configuration
features:
  # Jet features
  jet_features:
    - "jet_pt"
    - "jet_eta"
    - "jet_phi"
    - "jet_mass"
    - "jet_btag_score"
    - "jet_id"

  # MET features
  met_features:
    - "met_pt"
    - "met_phi"
    - "met_significance"

  # Event features
  event_features:
    - "n_jets"
    - "n_bjets"
    - "n_muons"
    - "n_electrons"
    - "n_taus"
    - "ht"
    - "st"

  # Derived features
  derived_features:
    - "delta_phi_met_jet"
    - "delta_phi_met_jet2"
    - "delta_phi_met_jet3"
    - "jet1_pt"
    - "jet2_pt"
    - "jet3_pt"
    - "jet4_pt"

  # Parametric input
  parametric_input:
    - "signal_mass"  # Signal mass parameter for parametric training

# Training data configuration
data:
  # Signal samples
  signal:
    samples:
      - name: "signal_1000"
        file: "signals/signal_1000.root"
        mass: 1000
        weight: 1.0
      - name: "signal_1200"
        file: "signals/signal_1200.root"
        mass: 1200
        weight: 1.0
      - name: "signal_1400"
        file: "signals/signal_1400.root"
        mass: 1400
        weight: 1.0
      - name: "signal_1600"
        file: "signals/signal_1600.root"
        mass: 1600
        weight: 1.0
      - name: "signal_1800"
        file: "signals/signal_1800.root"
        mass: 1800
        weight: 1.0
      - name: "signal_2000"
        file: "signals/signal_2000.root"
        mass: 2000
        weight: 1.0

  # Background samples
  background:
    samples:
      - name: "ttbar"
        file: "backgrounds/ttbar.root"
        weight: 1.0
      - name: "wjets"
        file: "backgrounds/wjets.root"
        weight: 1.0
      - name: "zjets"
        file: "backgrounds/zjets.root"
        weight: 1.0
      - name: "qcd"
        file: "backgrounds/qcd.root"
        weight: 1.0
      - name: "st"
        file: "backgrounds/st.root"
        weight: 1.0

  # Data loading
  max_events_per_sample: 100000  # Limit events per sample for training
  balance_classes: true  # Balance signal and background samples
  signal_background_ratio: 0.5  # Target ratio of signal to background

# Model evaluation
evaluation:
  # Validation metrics
  validation_metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "auc"
    - "roc_auc"

  # ROC curve
  roc_curve: true
  roc_thresholds: 100

  # Efficiency curves
  efficiency_curves: true
  signal_efficiency_points: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
  background_rejection_points: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# Output configuration
output:
  model_path: "outputs/models/dnn_model.pt"
  results_path: "outputs/dnn_results.json"
  plots_path: "outputs/plots/dnn/"

  # Save model components
  save_model: true
  save_optimizer: false
  save_training_history: true
  save_feature_importance: true

  # Export formats
  export_formats:
    - "pytorch"  # .pt file
    - "onnx"     # .onnx file for inference
    - "tflite"   # .tflite file for mobile deployment

# Advanced training options
advanced:
  # Learning rate scheduling
  lr_scheduler:
    type: "reduce_on_plateau"
    factor: 0.5
    patience: 5
    min_lr: 1e-6

  # Data augmentation
  data_augmentation:
    enabled: false
    noise_level: 0.01
    rotation_angle: 0.1

  # Regularization
  regularization:
    l1_lambda: 0.0
    l2_lambda: 0.001

  # Gradient clipping
  gradient_clipping:
    enabled: true
    max_norm: 1.0

  # Mixed precision training
  mixed_precision: false

  # Distributed training
  distributed:
    enabled: false
    backend: "nccl"
    world_size: 1

# Hardware configuration
hardware:
  device: "auto"  # auto, cpu, cuda, mps
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2

# Logging and monitoring
logging:
  level: "INFO"
  log_frequency: 10  # Log every N epochs
  save_checkpoints: true
  checkpoint_frequency: 10  # Save checkpoint every N epochs

  # TensorBoard logging
  tensorboard:
    enabled: true
    log_dir: "outputs/tensorboard/"
    log_frequency: 1  # Log every N epochs

# Model interpretation
interpretation:
  # Feature importance
  feature_importance:
    method: "permutation"  # permutation, shap, lime
    n_samples: 1000

  # SHAP analysis
  shap:
    enabled: true
    n_samples: 1000
    max_features: 20

  # LIME analysis
  lime:
    enabled: false
    n_samples: 1000
    n_features: 10

